#!/usr/bin/env python3
"""
ğŸ›ï¸ MASTER EXTRACTOR CONTROLLER - EL CEREBRO DE EXTRACCIÃ“N
Controla y ejecuta TODOS los extractores al mÃ¡ximo rendimiento
Â¡Crecimiento exponencial de la base de datos!
"""

import asyncio
import logging
import json
import time
from datetime import datetime
from motor.motor_asyncio import AsyncIOMotorClient
import os
from typing import Dict, Any

# Configurar logging
logging.basicConfig(level=logging.INFO)
logger = logging.getLogger(__name__)

class MasterExtractorController:
    def __init__(self):
        self.mongo_client = None
        self.db = None
        self.extractores_activos = {}
        self.stats_globales = {
            'total_extraido_hoy': 0,
            'fuentes_activas': 0,
            'extractores_ejecutados': 0,
            'tiempo_total_extraccion': 0,
            'empresas_nuevas': 0,
            'personas_nuevas': 0
        }
        
    async def initialize(self):
        """Inicializar controlador maestro"""
        try:
            mongo_url = os.environ.get('MONGO_URL', 'mongodb://localhost:27017')
            self.mongo_client = AsyncIOMotorClient(mongo_url)
            self.db = self.mongo_client[os.environ.get('DB_NAME', 'test_database')]
            
            logger.info("ğŸ›ï¸ MASTER EXTRACTOR CONTROLLER INICIALIZADO")
            logger.info("âš¡ PREPARANDO PARA DOMINACIÃ“N TOTAL DE DATOS")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error inicializando controlador: {e}")
            return False
    
    async def activar_extractor_ultra_empresarial(self):
        """ğŸ”¥ Activar Ultra Empresarial Extractor"""
        logger.info("ğŸ”¥ ACTIVANDO ULTRA EMPRESARIAL EXTRACTOR")
        
        try:
            from ultra_empresarial_extractor import ejecutar_extraccion_empresarial
            
            inicio = time.time()
            stats = await ejecutar_extraccion_empresarial()
            duracion = time.time() - inicio
            
            if stats:
                self.stats_globales['empresas_nuevas'] += stats['empresas_extraidas']
                self.stats_globales['extractores_ejecutados'] += 1
                self.stats_globales['tiempo_total_extraccion'] += duracion
                self.stats_globales['fuentes_activas'] += stats['fuentes_consultadas']
                
                logger.info(f"âœ… ULTRA EMPRESARIAL: {stats['empresas_extraidas']:,} empresas extraÃ­das")
                return True
            
        except Exception as e:
            logger.error(f"âŒ Error en Ultra Empresarial: {e}")
            
        return False
    
    async def activar_fast_2m_extractor(self):
        """âš¡ Activar Fast 2M Extractor"""
        logger.info("âš¡ ACTIVANDO FAST 2M EXTRACTOR")
        
        try:
            from fast_2m_extractor import Fast2MExtractor
            
            extractor = Fast2MExtractor()
            await extractor.initialize()
            
            # Ejecutar extracciÃ³n rÃ¡pida adicional
            inicio = time.time()
            resultado = await extractor.run_fast_extraction()
            duracion = time.time() - inicio
            
            if resultado and resultado.get('exito'):
                nuevos_registros = resultado.get('registros_finales', 0)
                self.stats_globales['personas_nuevas'] += nuevos_registros
                self.stats_globales['extractores_ejecutados'] += 1
                self.stats_globales['tiempo_total_extraccion'] += duracion
                
                logger.info(f"âœ… FAST 2M: {nuevos_registros:,} registros agregados")
                return True
                
        except Exception as e:
            logger.error(f"âŒ Error en Fast 2M: {e}")
            
        return False
    
    async def activar_ultra_deep_extractor(self):
        """ğŸ•³ï¸ Activar Ultra Deep Extractor"""
        logger.info("ğŸ•³ï¸ ACTIVANDO ULTRA DEEP EXTRACTOR")
        
        try:
            from ultra_deep_extractor import UltraDeepExtractor
            
            extractor = UltraDeepExtractor()
            await extractor.initialize()
            
            inicio = time.time()
            await extractor.execute_ultra_deep_extraction_immediate()
            duracion = time.time() - inicio
            
            self.stats_globales['extractores_ejecutados'] += 1
            self.stats_globales['tiempo_total_extraccion'] += duracion
            
            logger.info("âœ… ULTRA DEEP: ExtracciÃ³n profunda ejecutada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error en Ultra Deep: {e}")
            
        return False
    
    async def activar_mega_aggressive_extractor(self):
        """ğŸ’¥ Activar Mega Aggressive Extractor"""
        logger.info("ğŸ’¥ ACTIVANDO MEGA AGGRESSIVE EXTRACTOR")
        
        try:
            from mega_aggressive_extractor import MegaAggressiveExtractor
            
            extractor = MegaAggressiveExtractor()
            await extractor.initialize()
            
            inicio = time.time()
            # Ejecutar extracciÃ³n agresiva
            result = await extractor.run_mega_aggressive_extraction()
            duracion = time.time() - inicio
            
            if result:
                self.stats_globales['extractores_ejecutados'] += 1
                self.stats_globales['tiempo_total_extraccion'] += duracion
                
                logger.info("âœ… MEGA AGGRESSIVE: ExtracciÃ³n agresiva completada")
                return True
                
        except Exception as e:
            logger.error(f"âŒ Error en Mega Aggressive: {e}")
            
        return False
    
    async def activar_daticos_extractor(self):
        """ğŸ“Š Activar Daticos Extractor Avanzado"""
        logger.info("ğŸ“Š ACTIVANDO DATICOS EXTRACTOR AVANZADO")
        
        try:
            from advanced_daticos_extractor import AdvancedDaticosExtractor
            
            extractor = AdvancedDaticosExtractor()
            await extractor.initialize()
            
            inicio = time.time()
            # Usar credenciales reales
            await extractor.login_and_extract_massive("CABEZAS", "Hola2022")
            await extractor.login_and_extract_massive("Saraya", "12345")
            duracion = time.time() - inicio
            
            self.stats_globales['extractores_ejecutados'] += 1
            self.stats_globales['tiempo_total_extraccion'] += duracion
            
            logger.info("âœ… DATICOS: ExtracciÃ³n avanzada completada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error en Daticos: {e}")
            
        return False
    
    async def activar_registro_nacional_extractor(self):
        """ğŸ“‹ Activar Registro Nacional Extractor"""
        logger.info("ğŸ“‹ ACTIVANDO REGISTRO NACIONAL EXTRACTOR")
        
        try:
            from registro_nacional_extractor import RegistroNacionalExtractor
            
            extractor = RegistroNacionalExtractor()
            await extractor.initialize()
            
            inicio = time.time()
            await extractor.extract_massive_registry_data()
            duracion = time.time() - inicio
            
            self.stats_globales['extractores_ejecutados'] += 1
            self.stats_globales['tiempo_total_extraccion'] += duracion
            
            logger.info("âœ… REGISTRO NACIONAL: ExtracciÃ³n masiva completada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error en Registro Nacional: {e}")
            
        return False
    
    async def activar_portal_datos_abiertos(self):
        """ğŸŒ Activar Portal Datos Abiertos Extractor"""
        logger.info("ğŸŒ ACTIVANDO PORTAL DATOS ABIERTOS EXTRACTOR")
        
        try:
            from portal_datos_abiertos_extractor import PortalDatosAbiertosExtractor
            
            extractor = PortalDatosAbiertosExtractor()
            await extractor.initialize()
            
            inicio = time.time()
            await extractor.extract_all_government_data()
            duracion = time.time() - inicio
            
            self.stats_globales['extractores_ejecutados'] += 1
            self.stats_globales['tiempo_total_extraccion'] += duracion
            
            logger.info("âœ… PORTAL DATOS ABIERTOS: ExtracciÃ³n gubernamental completada")
            return True
            
        except Exception as e:
            logger.error(f"âŒ Error en Portal Datos Abiertos: {e}")
            
        return False
    
    async def contar_registros_actuales(self):
        """ğŸ“Š Contar registros totales actuales"""
        try:
            collections_principales = [
                'personas_fisicas_fast2m',
                'personas_juridicas_fast2m',
                'empresas_sicop_ultra',
                'empresas_hacienda_ultra',
                'empresas_registro_nacional_ultra',
                'empresas_meic_ultra',
                'empresas_ccss_ultra',
                'tse_datos_hibridos',
                'ultra_deep_extraction'
            ]
            
            total = 0
            desglose = {}
            
            for collection_name in collections_principales:
                try:
                    count = await self.db[collection_name].count_documents({})
                    if count > 0:
                        desglose[collection_name] = count
                        total += count
                except:
                    pass
            
            return total, desglose
            
        except Exception as e:
            logger.error(f"Error contando registros: {e}")
            return 0, {}
    
    async def ejecutar_extraccion_masiva_paralela(self):
        """ğŸš€ EJECUTAR TODOS LOS EXTRACTORES EN PARALELO - MÃXIMO RENDIMIENTO"""
        logger.info("ğŸ”¥ INICIANDO EXTRACCIÃ“N MASIVA PARALELA")
        logger.info("âš¡ TODOS LOS EXTRACTORES A MÃXIMO RENDIMIENTO")
        
        # Contar registros antes
        registros_antes, _ = await self.contar_registros_actuales()
        logger.info(f"ğŸ“Š REGISTROS ANTES: {registros_antes:,}")
        
        inicio_total = time.time()
        
        # EJECUTAR TODOS LOS EXTRACTORES EN PARALELO
        tareas_extraction = [
            self.activar_extractor_ultra_empresarial(),  # NUEVO - Empresarial masivo
            self.activar_fast_2m_extractor(),           # Personas rÃ¡pidas
            self.activar_ultra_deep_extractor(),        # ExtracciÃ³n profunda
            self.activar_mega_aggressive_extractor(),   # Agresivo
            self.activar_daticos_extractor(),           # Daticos avanzado
            self.activar_registro_nacional_extractor(), # Registro Nacional
            self.activar_portal_datos_abiertos()        # Datos gubernamentales
        ]
        
        logger.info(f"âš¡ Ejecutando {len(tareas_extraction)} extractores en paralelo...")
        
        # Ejecutar todas las tareas
        resultados = await asyncio.gather(*tareas_extraction, return_exceptions=True)
        
        # Procesar resultados
        extractores_exitosos = sum(1 for r in resultados if r is True)
        extractores_fallidos = len(resultados) - extractores_exitosos
        
        # Contar registros despuÃ©s
        registros_despues, desglose = await self.contar_registros_actuales()
        registros_agregados = registros_despues - registros_antes
        
        # EstadÃ­sticas finales
        duracion_total = time.time() - inicio_total
        
        logger.info("ğŸ‰ EXTRACCIÃ“N MASIVA PARALELA COMPLETADA")
        logger.info("=" * 80)
        logger.info(f"â±ï¸  TIEMPO TOTAL: {duracion_total/60:.2f} minutos")
        logger.info(f"âœ… EXTRACTORES EXITOSOS: {extractores_exitosos}")
        logger.info(f"âŒ EXTRACTORES FALLIDOS: {extractores_fallidos}")
        logger.info(f"ğŸ“Š REGISTROS ANTES: {registros_antes:,}")
        logger.info(f"ğŸ“Š REGISTROS DESPUÃ‰S: {registros_despues:,}")
        logger.info(f"ğŸš€ REGISTROS AGREGADOS: {registros_agregados:,}")
        logger.info(f"ğŸ“ˆ CRECIMIENTO: {((registros_agregados/max(registros_antes,1))*100):.2f}%")
        logger.info("=" * 80)
        
        logger.info("ğŸ“‹ DESGLOSE POR COLECCIÃ“N:")
        for collection, count in desglose.items():
            logger.info(f"   â€¢ {collection}: {count:,}")
        
        # Actualizar estadÃ­sticas globales
        self.stats_globales.update({
            'total_extraido_hoy': registros_agregados,
            'registros_antes': registros_antes,
            'registros_despues': registros_despues,
            'extractores_exitosos': extractores_exitosos,
            'extractores_fallidos': extractores_fallidos,
            'duracion_total_minutos': duracion_total/60,
            'desglose_colecciones': desglose
        })
        
        # Guardar estadÃ­sticas en MongoDB
        await self.guardar_estadisticas_extraccion()
        
        return self.stats_globales
    
    async def guardar_estadisticas_extraccion(self):
        """ğŸ’¾ Guardar estadÃ­sticas de extracciÃ³n"""
        try:
            stats_record = {
                **self.stats_globales,
                'fecha_extraccion': datetime.now().isoformat(),
                'timestamp': datetime.now()
            }
            
            collection = self.db['estadisticas_extraccion_masiva']
            await collection.insert_one(stats_record)
            
            logger.info("ğŸ’¾ EstadÃ­sticas de extracciÃ³n guardadas")
            
        except Exception as e:
            logger.error(f"Error guardando estadÃ­sticas: {e}")
    
    async def ejecutar_todos_extractores(self):
        """ğŸš€ Ejecutar TODOS los extractores en paralelo para mÃ¡ximo rendimiento"""
        logger.info("ğŸš€ EJECUTANDO TODOS LOS EXTRACTORES EN PARALELO")
        
        inicio_total = time.time()
        resultados = []
        
        # Lista de tareas de extracciÃ³n
        tareas = [
            ("Ultra Empresarial", self.activar_extractor_ultra_empresarial),
            ("Fast 2M", self.activar_fast_2m_extractor),
            ("Ultra Deep", self.activar_ultra_deep_extractor),
            ("Mega Aggressive", self.activar_mega_aggressive_extractor),
            ("Daticos Extractor", self.activar_daticos_extractor)
        ]
        
        # Ejecutar en paralelo con lÃ­mite de concurrencia
        semaforo = asyncio.Semaphore(3)  # Max 3 extractores simultÃ¡neos
        
        async def ejecutar_con_limite(nombre, funcion):
            async with semaforo:
                logger.info(f"ğŸ¯ Iniciando {nombre}")
                try:
                    resultado = await funcion()
                    return {"extractor": nombre, "exito": resultado, "error": None}
                except Exception as e:
                    logger.error(f"âŒ Error en {nombre}: {e}")
                    return {"extractor": nombre, "exito": False, "error": str(e)}
        
        # Crear tareas paralelas
        tasks = [ejecutar_con_limite(nombre, funcion) for nombre, funcion in tareas]
        
        # Esperar resultados
        resultados = await asyncio.gather(*tasks, return_exceptions=True)
        
        # Procesar resultados
        extractores_exitosos = 0
        extractores_fallidos = 0
        
        for resultado in resultados:
            if isinstance(resultado, dict):
                if resultado.get('exito'):
                    extractores_exitosos += 1
                else:
                    extractores_fallidos += 1
        
        duracion_total = time.time() - inicio_total
        
        # Actualizar estadÃ­sticas globales
        self.stats_globales['extractores_ejecutados'] = extractores_exitosos
        self.stats_globales['tiempo_total_extraccion'] = duracion_total
        
        # EstadÃ­sticas finales
        logger.info("ğŸ‰ EJECUCIÃ“N MASIVA COMPLETADA")
        logger.info("=" * 60)
        logger.info(f"âš¡ Extractores exitosos: {extractores_exitosos}")
        logger.info(f"âŒ Extractores fallidos: {extractores_fallidos}")
        logger.info(f"â±ï¸  Tiempo total: {duracion_total/60:.2f} minutos")
        logger.info(f"ğŸ“Š Stats globales: {self.stats_globales}")
        logger.info("=" * 60)
        
        return {
            "exito": extractores_exitosos > 0,
            "extractores_exitosos": extractores_exitosos,
            "extractores_fallidos": extractores_fallidos,
            "tiempo_minutos": duracion_total / 60,
            "stats_globales": self.stats_globales,
            "resultados_detallados": [r for r in resultados if isinstance(r, dict)]
        }
    
    async def cerrar_conexiones(self):
        """Cerrar conexiones"""
        if self.mongo_client:
            self.mongo_client.close()

# FunciÃ³n principal
async def ejecutar_master_extractor():
    """ğŸ›ï¸ Ejecutar Master Extractor Controller"""
    controller = MasterExtractorController()
    
    try:
        await controller.initialize()
        stats = await controller.ejecutar_extraccion_masiva_paralela()
        return stats
    finally:
        await controller.cerrar_conexiones()

if __name__ == "__main__":
    logger.info("ğŸ›ï¸ INICIANDO MASTER EXTRACTOR CONTROLLER")
    logger.info("ğŸ”¥ PREPARANDO PARA EXTRACCIÃ“N MASIVA")
    
    stats = asyncio.run(ejecutar_master_extractor())
    
    logger.info("ğŸ‰ MASTER EXTRACTOR CONTROLLER COMPLETADO")
    logger.info(f"ğŸ“Š ESTADÃSTICAS FINALES: {json.dumps(stats, indent=2, default=str)}")